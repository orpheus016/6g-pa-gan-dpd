{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139488e6",
   "metadata": {},
   "source": [
    "# üéØ 6G PA DPD Training Notebook\n",
    "## CWGAN-GP + A-SPSA for 29th LSI Design Contest\n",
    "\n",
    "This notebook trains a **Time-Delay Neural Network (TDNN)** for Digital Predistortion using:\n",
    "- **CWGAN-GP**: Conditional Wasserstein GAN with Gradient Penalty\n",
    "- **Spectral Loss**: EVM + ACPR optimization\n",
    "- **QAT**: Quantization-Aware Training for FPGA deployment\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "Input (18) ‚Üí FC(32) ‚Üí LeakyReLU ‚Üí FC(16) ‚Üí LeakyReLU ‚Üí FC(2) ‚Üí Tanh ‚Üí Output\n",
    "```\n",
    "\n",
    "**Target**: PYNQ-Z1 / ZCU104 FPGA with HDMI loopback demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e95ba60",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72607f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (run once)\n",
    "!git clone https://github.com/YOUR_USERNAME/6g-pa-gan-dpd.git 2>/dev/null || echo \"Already cloned\"\n",
    "%cd 6g-pa-gan-dpd\n",
    "\n",
    "# Install minimal dependencies (most are pre-installed on Colab)\n",
    "!pip install -q h5py pyyaml tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab2fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2c73e",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c37341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "with open('config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Display key parameters\n",
    "print(\"=\" * 50)\n",
    "print(\"Configuration Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Sample Rate: {config['system']['sample_rate_mhz']} MHz\")\n",
    "print(f\"TDNN Architecture: {config['model']['generator']['input_dim']} ‚Üí \"\n",
    "      f\"{config['model']['generator']['hidden_dims']} ‚Üí \"\n",
    "      f\"{config['model']['generator']['output_dim']}\")\n",
    "print(f\"Quantization: {config['quantization']['weight_bits']}-bit weights\")\n",
    "print(f\"Batch Size: {config['training']['batch_size']}\")\n",
    "print(f\"Learning Rate: {config['training']['learning_rate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c39fb",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TDNNGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Time-Delay Neural Network Generator for DPD.\n",
    "    Memory-aware architecture with envelope features.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=18, hidden_dims=[32, 16], output_dim=2, \n",
    "                 quantize=False, num_bits=16):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.quantize = quantize\n",
    "        self.num_bits = num_bits\n",
    "        \n",
    "        # Build layers\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            layers.append(nn.LeakyReLU(0.25))  # 0.25 for easy shift in HW\n",
    "            in_dim = hidden_dim\n",
    "            \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.output = nn.Linear(in_dim, output_dim)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, a=0.25)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq, input_dim] or [batch, input_dim]\n",
    "        if x.dim() == 3:\n",
    "            batch, seq, _ = x.shape\n",
    "            x = x.reshape(-1, self.input_dim)\n",
    "            reshape_back = True\n",
    "        else:\n",
    "            reshape_back = False\n",
    "            batch = x.shape[0]\n",
    "            seq = 1\n",
    "            \n",
    "        # Forward pass\n",
    "        h = self.features(x)\n",
    "        out = self.tanh(self.output(h))\n",
    "        \n",
    "        if reshape_back:\n",
    "            out = out.reshape(batch, seq, -1)\n",
    "            \n",
    "        return out\n",
    "\n",
    "# Count parameters\n",
    "model = TDNNGenerator(input_dim=18, hidden_dims=[32, 16], output_dim=2)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"TDNN Generator: {total_params:,} parameters\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"  {name}: {list(param.shape)} = {param.numel()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb17aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"CWGAN-GP Critic with spectral normalization.\"\"\"\n",
    "    def __init__(self, input_dim=4, hidden_dims=[64, 32, 16]):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.utils.spectral_norm(nn.Linear(in_dim, hidden_dim)))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "            in_dim = hidden_dim\n",
    "            \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.output = nn.utils.spectral_norm(nn.Linear(in_dim, 1))\n",
    "        \n",
    "    def forward(self, x, condition):\n",
    "        # Concatenate PA output and condition\n",
    "        combined = torch.cat([x, condition], dim=-1)\n",
    "        h = self.features(combined)\n",
    "        return self.output(h)\n",
    "\n",
    "disc = Discriminator()\n",
    "print(f\"Discriminator: {sum(p.numel() for p in disc.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce008ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PADigitalTwin(nn.Module):\n",
    "    \"\"\"\n",
    "    PA Digital Twin using Volterra model.\n",
    "    Models AM-AM, AM-PM, and memory effects.\n",
    "    \"\"\"\n",
    "    def __init__(self, memory_depth=5, nonlin_order=5):\n",
    "        super().__init__()\n",
    "        self.memory_depth = memory_depth\n",
    "        self.nonlin_order = nonlin_order\n",
    "        \n",
    "        # Volterra coefficients (learnable or fixed)\n",
    "        self.register_buffer('alpha1', torch.tensor(0.95))   # Linear gain\n",
    "        self.register_buffer('alpha3', torch.tensor(-0.12))  # 3rd order\n",
    "        self.register_buffer('alpha5', torch.tensor(0.03))   # 5th order\n",
    "        self.register_buffer('beta', torch.tensor(0.15))     # AM-PM\n",
    "        \n",
    "        # Memory coefficients\n",
    "        mem_coef = torch.tensor([1.0, 0.3, 0.1, 0.05, 0.02])\n",
    "        self.register_buffer('memory_coef', mem_coef / mem_coef.sum())\n",
    "        \n",
    "    def forward(self, x, temperature_state=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Complex input [batch, seq, 2] (I, Q)\n",
    "            temperature_state: 0=cold, 1=normal, 2=hot\n",
    "        \"\"\"\n",
    "        # Apply temperature drift\n",
    "        temp_scale = 1.0 + 0.05 * (temperature_state - 1)\n",
    "        \n",
    "        # Get I/Q components\n",
    "        x_i = x[..., 0]\n",
    "        x_q = x[..., 1]\n",
    "        \n",
    "        # Complex magnitude\n",
    "        mag_sq = x_i**2 + x_q**2\n",
    "        mag = torch.sqrt(mag_sq + 1e-8)\n",
    "        \n",
    "        # AM-AM: Polynomial compression\n",
    "        gain = self.alpha1 + self.alpha3 * mag_sq + self.alpha5 * mag_sq**2\n",
    "        gain = gain * temp_scale\n",
    "        \n",
    "        # AM-PM: Phase rotation\n",
    "        phase_shift = self.beta * mag_sq * temp_scale\n",
    "        cos_phi = torch.cos(phase_shift)\n",
    "        sin_phi = torch.sin(phase_shift)\n",
    "        \n",
    "        # Apply gain and phase\n",
    "        y_i = gain * (x_i * cos_phi - x_q * sin_phi)\n",
    "        y_q = gain * (x_i * sin_phi + x_q * cos_phi)\n",
    "        \n",
    "        # Memory effects (simplified FIR)\n",
    "        if x.dim() == 3 and x.shape[1] >= self.memory_depth:\n",
    "            y_i_mem = F.conv1d(\n",
    "                y_i.unsqueeze(1), \n",
    "                self.memory_coef.view(1, 1, -1),\n",
    "                padding=self.memory_depth // 2\n",
    "            ).squeeze(1)[..., :y_i.shape[-1]]\n",
    "            y_q_mem = F.conv1d(\n",
    "                y_q.unsqueeze(1),\n",
    "                self.memory_coef.view(1, 1, -1),\n",
    "                padding=self.memory_depth // 2\n",
    "            ).squeeze(1)[..., :y_q.shape[-1]]\n",
    "        else:\n",
    "            y_i_mem = y_i\n",
    "            y_q_mem = y_q\n",
    "            \n",
    "        return torch.stack([y_i_mem, y_q_mem], dim=-1)\n",
    "\n",
    "pa = PADigitalTwin()\n",
    "print(\"PA Digital Twin created (Volterra model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e070c1",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e6bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_memory_features(x, memory_depth=5):\n",
    "    \"\"\"\n",
    "    Create input features for TDNN including memory taps and envelope.\n",
    "    \n",
    "    Input: x [batch, seq, 2] (I, Q)\n",
    "    Output: features [batch, seq, 18]\n",
    "        - Current I/Q: 2\n",
    "        - Delayed I/Q (3 taps): 6  \n",
    "        - Envelope features |x|^2, |x|^4 (5 taps): 10\n",
    "    \"\"\"\n",
    "    batch, seq, _ = x.shape\n",
    "    \n",
    "    # Pad for delays\n",
    "    x_padded = F.pad(x, (0, 0, memory_depth-1, 0), mode='replicate')\n",
    "    \n",
    "    features_list = []\n",
    "    \n",
    "    # Current I/Q\n",
    "    features_list.append(x)  # [batch, seq, 2]\n",
    "    \n",
    "    # Delayed I/Q (taps 1, 2, 3)\n",
    "    for d in range(1, 4):\n",
    "        delayed = x_padded[:, memory_depth-1-d:memory_depth-1-d+seq, :]\n",
    "        features_list.append(delayed)\n",
    "    \n",
    "    # Envelope features: |x[n-k]|^2 and |x[n-k]|^4 for k=0..4\n",
    "    for d in range(5):\n",
    "        if d == 0:\n",
    "            tap = x\n",
    "        else:\n",
    "            tap = x_padded[:, memory_depth-1-d:memory_depth-1-d+seq, :]\n",
    "        \n",
    "        mag_sq = tap[..., 0]**2 + tap[..., 1]**2  # |x|^2\n",
    "        mag_4 = mag_sq ** 2  # |x|^4\n",
    "        \n",
    "        features_list.append(mag_sq.unsqueeze(-1))\n",
    "        features_list.append(mag_4.unsqueeze(-1))\n",
    "    \n",
    "    # Concatenate all features\n",
    "    features = torch.cat(features_list, dim=-1)  # [batch, seq, 18]\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Test feature creation\n",
    "test_x = torch.randn(4, 64, 2)\n",
    "test_features = create_memory_features(test_x)\n",
    "print(f\"Input shape: {test_x.shape}\")\n",
    "print(f\"Features shape: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba15fd",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f21c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_evm(reference, signal):\n",
    "    \"\"\"Compute Error Vector Magnitude (lower is better).\"\"\"\n",
    "    error = signal - reference\n",
    "    error_power = (error ** 2).sum(dim=-1).mean()\n",
    "    ref_power = (reference ** 2).sum(dim=-1).mean()\n",
    "    evm = torch.sqrt(error_power / (ref_power + 1e-8))\n",
    "    return evm\n",
    "\n",
    "def compute_nmse(reference, signal):\n",
    "    \"\"\"Compute Normalized Mean Square Error.\"\"\"\n",
    "    error = signal - reference\n",
    "    nmse = (error ** 2).sum() / (reference ** 2).sum()\n",
    "    return nmse\n",
    "\n",
    "def compute_acpr(signal, main_bw_ratio=0.8, adj_bw_ratio=0.1):\n",
    "    \"\"\"Compute Adjacent Channel Power Ratio.\"\"\"\n",
    "    # Complex signal\n",
    "    sig_complex = signal[..., 0] + 1j * signal[..., 1]\n",
    "    \n",
    "    # FFT\n",
    "    spectrum = torch.fft.fft(sig_complex, dim=-1)\n",
    "    power = (spectrum.real**2 + spectrum.imag**2)\n",
    "    \n",
    "    n_fft = power.shape[-1]\n",
    "    \n",
    "    # Main channel (center)\n",
    "    main_start = int(n_fft * (0.5 - main_bw_ratio/2))\n",
    "    main_end = int(n_fft * (0.5 + main_bw_ratio/2))\n",
    "    main_power = power[..., main_start:main_end].sum()\n",
    "    \n",
    "    # Adjacent channels\n",
    "    adj_lower = power[..., :int(n_fft * adj_bw_ratio)].sum()\n",
    "    adj_upper = power[..., -int(n_fft * adj_bw_ratio):].sum()\n",
    "    adj_power = adj_lower + adj_upper\n",
    "    \n",
    "    acpr = 10 * torch.log10(adj_power / (main_power + 1e-8))\n",
    "    return acpr\n",
    "\n",
    "class SpectralLoss(nn.Module):\n",
    "    \"\"\"Combined spectral loss: EVM + ACPR + NMSE.\"\"\"\n",
    "    def __init__(self, evm_weight=1.0, acpr_weight=0.5, nmse_weight=1.0):\n",
    "        super().__init__()\n",
    "        self.evm_weight = evm_weight\n",
    "        self.acpr_weight = acpr_weight\n",
    "        self.nmse_weight = nmse_weight\n",
    "        \n",
    "    def forward(self, reference, signal):\n",
    "        evm = compute_evm(reference, signal)\n",
    "        nmse = compute_nmse(reference, signal)\n",
    "        acpr = compute_acpr(signal)\n",
    "        \n",
    "        # ACPR is in dB (negative), we want to minimize it (make more negative)\n",
    "        # So we add it (or use -acpr to maximize suppression)\n",
    "        loss = (self.evm_weight * evm + \n",
    "                self.nmse_weight * nmse - \n",
    "                self.acpr_weight * acpr / 50)  # Normalize ACPR contribution\n",
    "        \n",
    "        return loss, {'evm': evm.item(), 'nmse': nmse.item(), 'acpr': acpr.item()}\n",
    "\n",
    "spectral_loss = SpectralLoss()\n",
    "print(\"Spectral loss function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(disc, real, fake, condition, device):\n",
    "    \"\"\"WGAN-GP gradient penalty.\"\"\"\n",
    "    alpha = torch.rand(real.size(0), 1, 1, device=device)\n",
    "    interpolates = alpha * real + (1 - alpha) * fake\n",
    "    interpolates.requires_grad_(True)\n",
    "    \n",
    "    d_interp = disc(interpolates, condition)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interp,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interp),\n",
    "        create_graph=True,\n",
    "        retain_graph=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.reshape(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c53a7",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Generate Synthetic Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e125b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ofdm_signal(batch_size, seq_len, num_subcarriers=64):\n",
    "    \"\"\"\n",
    "    Generate OFDM-like signal for training.\n",
    "    \"\"\"\n",
    "    # Random QAM symbols\n",
    "    qam_symbols = (torch.randint(0, 4, (batch_size, num_subcarriers)) * 2 - 3) + \\\n",
    "                  1j * (torch.randint(0, 4, (batch_size, num_subcarriers)) * 2 - 3)\n",
    "    qam_symbols = qam_symbols / torch.abs(qam_symbols).max()\n",
    "    \n",
    "    # IFFT to get time domain\n",
    "    time_signal = torch.fft.ifft(qam_symbols, n=seq_len, dim=-1)\n",
    "    \n",
    "    # Stack I/Q\n",
    "    signal = torch.stack([time_signal.real, time_signal.imag], dim=-1)\n",
    "    \n",
    "    # Normalize\n",
    "    signal = signal / (signal.abs().max() + 1e-8) * 0.8\n",
    "    \n",
    "    return signal.float()\n",
    "\n",
    "# Generate test batch\n",
    "test_signal = generate_ofdm_signal(8, 256)\n",
    "print(f\"Generated signal shape: {test_signal.shape}\")\n",
    "print(f\"Signal range: [{test_signal.min():.3f}, {test_signal.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee839bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize signal and PA distortion\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Time domain\n",
    "ax = axes[0, 0]\n",
    "ax.plot(test_signal[0, :100, 0].numpy(), label='I')\n",
    "ax.plot(test_signal[0, :100, 1].numpy(), label='Q')\n",
    "ax.set_title('Input Signal (Time Domain)')\n",
    "ax.legend()\n",
    "\n",
    "# Constellation\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(test_signal[0, :, 0].numpy(), test_signal[0, :, 1].numpy(), \n",
    "           alpha=0.5, s=5)\n",
    "ax.set_title('Input Constellation')\n",
    "ax.set_xlabel('I')\n",
    "ax.set_ylabel('Q')\n",
    "ax.axis('equal')\n",
    "\n",
    "# PA output\n",
    "pa_output = pa(test_signal)\n",
    "ax = axes[1, 0]\n",
    "ax.plot(pa_output[0, :100, 0].detach().numpy(), label='I')\n",
    "ax.plot(pa_output[0, :100, 1].detach().numpy(), label='Q')\n",
    "ax.set_title('PA Output (Distorted)')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(pa_output[0, :, 0].detach().numpy(), \n",
    "           pa_output[0, :, 1].detach().numpy(), \n",
    "           alpha=0.5, s=5)\n",
    "ax.set_title('PA Output Constellation (Distorted)')\n",
    "ax.set_xlabel('I')\n",
    "ax.set_ylabel('Q')\n",
    "ax.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute distortion metrics\n",
    "evm = compute_evm(test_signal, pa_output)\n",
    "print(f\"\\nPA Distortion Metrics (without DPD):\")\n",
    "print(f\"  EVM: {evm.item()*100:.2f}%\")\n",
    "print(f\"  EVM (dB): {20*np.log10(evm.item()):.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc5eef",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2777d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "NUM_EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "SEQ_LEN = 256\n",
    "LR_G = 1e-4\n",
    "LR_D = 1e-4\n",
    "N_CRITIC = 5  # Train discriminator N times per generator update\n",
    "GP_WEIGHT = 10.0\n",
    "SPECTRAL_WEIGHT = 0.5\n",
    "\n",
    "# Initialize models\n",
    "generator = TDNNGenerator(input_dim=18, hidden_dims=[32, 16], output_dim=2).to(device)\n",
    "discriminator = Discriminator(input_dim=4, hidden_dims=[64, 32, 16]).to(device)\n",
    "pa_model = PADigitalTwin().to(device)\n",
    "\n",
    "# Optimizers\n",
    "opt_g = torch.optim.Adam(generator.parameters(), lr=LR_G, betas=(0.5, 0.9))\n",
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr=LR_D, betas=(0.5, 0.9))\n",
    "\n",
    "# Loss\n",
    "spectral_loss_fn = SpectralLoss(evm_weight=1.0, acpr_weight=0.5, nmse_weight=1.0)\n",
    "\n",
    "print(\"Training setup complete!\")\n",
    "print(f\"  Generator params: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "print(f\"  Discriminator params: {sum(p.numel() for p in discriminator.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77449757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'd_loss': [], 'g_loss': [], 'evm': [], 'acpr': [], 'w_distance': []\n",
    "}\n",
    "\n",
    "# Training loop\n",
    "pbar = tqdm(range(NUM_EPOCHS), desc='Training')\n",
    "\n",
    "for epoch in pbar:\n",
    "    epoch_d_loss = 0\n",
    "    epoch_g_loss = 0\n",
    "    epoch_evm = 0\n",
    "    n_batches = 100  # Batches per epoch\n",
    "    \n",
    "    for batch_idx in range(n_batches):\n",
    "        # Generate training data\n",
    "        x_input = generate_ofdm_signal(BATCH_SIZE, SEQ_LEN).to(device)\n",
    "        \n",
    "        # Create memory features\n",
    "        features = create_memory_features(x_input)\n",
    "        \n",
    "        # ==================\n",
    "        # Train Discriminator\n",
    "        # ==================\n",
    "        for _ in range(N_CRITIC):\n",
    "            opt_d.zero_grad()\n",
    "            \n",
    "            # Generator output (predistorted signal)\n",
    "            with torch.no_grad():\n",
    "                dpd_output = generator(features)\n",
    "            \n",
    "            # PA output\n",
    "            pa_output = pa_model(dpd_output)\n",
    "            \n",
    "            # Real = ideal output (input signal)\n",
    "            # Fake = PA output after DPD\n",
    "            real_score = discriminator(x_input, x_input)\n",
    "            fake_score = discriminator(pa_output, x_input)\n",
    "            \n",
    "            # Wasserstein loss\n",
    "            d_loss = fake_score.mean() - real_score.mean()\n",
    "            \n",
    "            # Gradient penalty\n",
    "            gp = compute_gradient_penalty(discriminator, x_input, pa_output, x_input, device)\n",
    "            \n",
    "            # Total discriminator loss\n",
    "            d_total = d_loss + GP_WEIGHT * gp\n",
    "            d_total.backward()\n",
    "            opt_d.step()\n",
    "        \n",
    "        # ==================\n",
    "        # Train Generator\n",
    "        # ==================\n",
    "        opt_g.zero_grad()\n",
    "        \n",
    "        # Generate predistorted signal\n",
    "        dpd_output = generator(features)\n",
    "        \n",
    "        # PA output\n",
    "        pa_output = pa_model(dpd_output)\n",
    "        \n",
    "        # Adversarial loss (want discriminator to think PA output is real)\n",
    "        fake_score = discriminator(pa_output, x_input)\n",
    "        g_adv_loss = -fake_score.mean()\n",
    "        \n",
    "        # Spectral loss (EVM, ACPR)\n",
    "        g_spectral_loss, spectral_info = spectral_loss_fn(x_input, pa_output)\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_total = g_adv_loss + SPECTRAL_WEIGHT * g_spectral_loss\n",
    "        g_total.backward()\n",
    "        opt_g.step()\n",
    "        \n",
    "        # Accumulate metrics\n",
    "        epoch_d_loss += d_loss.item()\n",
    "        epoch_g_loss += g_total.item()\n",
    "        epoch_evm += spectral_info['evm']\n",
    "    \n",
    "    # Average metrics\n",
    "    epoch_d_loss /= n_batches\n",
    "    epoch_g_loss /= n_batches\n",
    "    epoch_evm /= n_batches\n",
    "    \n",
    "    # Record history\n",
    "    history['d_loss'].append(epoch_d_loss)\n",
    "    history['g_loss'].append(epoch_g_loss)\n",
    "    history['evm'].append(epoch_evm)\n",
    "    history['w_distance'].append(-epoch_d_loss)\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.set_postfix({\n",
    "        'D_loss': f'{epoch_d_loss:.4f}',\n",
    "        'G_loss': f'{epoch_g_loss:.4f}',\n",
    "        'EVM': f'{epoch_evm*100:.2f}%'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5501fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.plot(history['d_loss'], label='Discriminator')\n",
    "ax.plot(history['g_loss'], label='Generator')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.plot(history['w_distance'])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Wasserstein Distance')\n",
    "ax.set_title('Wasserstein Distance')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "ax.plot([e*100 for e in history['evm']])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('EVM (%)')\n",
    "ax.set_title('Error Vector Magnitude')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "ax.plot([20*np.log10(e) for e in history['evm']])\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('EVM (dB)')\n",
    "ax.set_title('EVM in dB (lower is better)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134fb95",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b54296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation\n",
    "generator.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate test signal\n",
    "    test_input = generate_ofdm_signal(1, 1024).to(device)\n",
    "    test_features = create_memory_features(test_input)\n",
    "    \n",
    "    # Without DPD\n",
    "    pa_no_dpd = pa_model(test_input)\n",
    "    \n",
    "    # With DPD\n",
    "    dpd_output = generator(test_features)\n",
    "    pa_with_dpd = pa_model(dpd_output)\n",
    "\n",
    "# Compute metrics\n",
    "evm_no_dpd = compute_evm(test_input, pa_no_dpd)\n",
    "evm_with_dpd = compute_evm(test_input, pa_with_dpd)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"Final Evaluation Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nWithout DPD:\")\n",
    "print(f\"  EVM: {evm_no_dpd.item()*100:.2f}% ({20*np.log10(evm_no_dpd.item()):.2f} dB)\")\n",
    "print(f\"\\nWith DPD:\")\n",
    "print(f\"  EVM: {evm_with_dpd.item()*100:.2f}% ({20*np.log10(evm_with_dpd.item()):.2f} dB)\")\n",
    "print(f\"\\nImprovement: {(evm_no_dpd.item() - evm_with_dpd.item())*100:.2f}% absolute\")\n",
    "print(f\"             {20*np.log10(evm_no_dpd.item()/evm_with_dpd.item()):.2f} dB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "\n",
    "test_input_np = test_input[0].cpu().numpy()\n",
    "pa_no_dpd_np = pa_no_dpd[0].cpu().numpy()\n",
    "pa_with_dpd_np = pa_with_dpd[0].cpu().numpy()\n",
    "\n",
    "# Constellation plots\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(test_input_np[:, 0], test_input_np[:, 1], alpha=0.5, s=5)\n",
    "ax.set_title('Input Signal')\n",
    "ax.set_xlabel('I')\n",
    "ax.set_ylabel('Q')\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(pa_no_dpd_np[:, 0], pa_no_dpd_np[:, 1], alpha=0.5, s=5, c='red')\n",
    "ax.set_title(f'Without DPD (EVM={evm_no_dpd.item()*100:.1f}%)')\n",
    "ax.set_xlabel('I')\n",
    "ax.set_ylabel('Q')\n",
    "ax.axis('equal')\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.scatter(pa_with_dpd_np[:, 0], pa_with_dpd_np[:, 1], alpha=0.5, s=5, c='green')\n",
    "ax.set_title(f'With DPD (EVM={evm_with_dpd.item()*100:.1f}%)')\n",
    "ax.set_xlabel('I')\n",
    "ax.set_ylabel('Q')\n",
    "ax.axis('equal')\n",
    "\n",
    "# Spectrum plots\n",
    "def plot_spectrum(ax, signal, title):\n",
    "    sig_complex = signal[:, 0] + 1j * signal[:, 1]\n",
    "    spectrum = np.fft.fftshift(np.fft.fft(sig_complex))\n",
    "    power_db = 20 * np.log10(np.abs(spectrum) + 1e-10)\n",
    "    freqs = np.fft.fftshift(np.fft.fftfreq(len(sig_complex)))\n",
    "    ax.plot(freqs, power_db)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Normalized Frequency')\n",
    "    ax.set_ylabel('Power (dB)')\n",
    "    ax.set_ylim(-60, 10)\n",
    "\n",
    "plot_spectrum(axes[1, 0], test_input_np, 'Input Spectrum')\n",
    "plot_spectrum(axes[1, 1], pa_no_dpd_np, 'Without DPD Spectrum')\n",
    "plot_spectrum(axes[1, 2], pa_with_dpd_np, 'With DPD Spectrum')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efeffdf",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Export Weights for FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b166247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_weights(weight, num_bits=16):\n",
    "    \"\"\"Quantize weights to fixed-point Q1.15 format.\"\"\"\n",
    "    scale = 2 ** (num_bits - 1) - 1\n",
    "    weight_clipped = torch.clamp(weight, -1.0, 1.0 - 1/scale)\n",
    "    weight_quantized = torch.round(weight_clipped * scale) / scale\n",
    "    return weight_quantized\n",
    "\n",
    "def export_weights_hex(model, filepath):\n",
    "    \"\"\"Export model weights to Verilog $readmemh format.\"\"\"\n",
    "    all_weights = []\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        w = param.detach().cpu()\n",
    "        w_quant = quantize_weights(w)\n",
    "        w_int = (w_quant * 32767).to(torch.int16)\n",
    "        all_weights.extend(w_int.flatten().tolist())\n",
    "        print(f\"  {name}: {list(w.shape)} = {w.numel()} params\")\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(f\"// TDNN Generator weights - {len(all_weights)} total\\n\")\n",
    "        f.write(f\"// Format: Q1.15 signed fixed-point\\n\\n\")\n",
    "        for w in all_weights:\n",
    "            if w < 0:\n",
    "                w = (1 << 16) + w\n",
    "            f.write(f\"{w:04X}\\n\")\n",
    "    \n",
    "    print(f\"\\nExported {len(all_weights)} weights to {filepath}\")\n",
    "\n",
    "# Export\n",
    "print(\"Exporting weights...\")\n",
    "export_weights_hex(generator, 'weights_trained.hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b882575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoint for later use\n",
    "checkpoint = {\n",
    "    'epoch': NUM_EPOCHS,\n",
    "    'generator_state_dict': generator.state_dict(),\n",
    "    'discriminator_state_dict': discriminator.state_dict(),\n",
    "    'optimizer_g_state_dict': opt_g.state_dict(),\n",
    "    'optimizer_d_state_dict': opt_d.state_dict(),\n",
    "    'history': history,\n",
    "    'config': {\n",
    "        'input_dim': 18,\n",
    "        'hidden_dims': [32, 16],\n",
    "        'output_dim': 2,\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'dpd_trained.pt')\n",
    "print(\"Checkpoint saved to dpd_trained.pt\")\n",
    "\n",
    "# Download files (for Colab)\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('weights_trained.hex')\n",
    "    files.download('dpd_trained.pt')\n",
    "    print(\"Files downloaded!\")\n",
    "except:\n",
    "    print(\"Not running on Colab - files saved locally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412c3f5",
   "metadata": {},
   "source": [
    "## üéØ Summary\n",
    "\n",
    "### Trained Model\n",
    "- **Architecture**: TDNN 18‚Üí32‚Üí16‚Üí2\n",
    "- **Parameters**: 1,170 (fits in ~2.4KB)\n",
    "- **Quantization**: Q1.15 (16-bit fixed-point)\n",
    "\n",
    "### Next Steps\n",
    "1. Download `weights_trained.hex`\n",
    "2. Copy to `rtl/weights/` folder\n",
    "3. Run RTL simulation: `cd rtl && make sim_all`\n",
    "4. Build FPGA bitstream in Vivado\n",
    "5. Run HDMI demo on PYNQ-Z1/ZCU104\n",
    "\n",
    "### Files Generated\n",
    "- `weights_trained.hex` - Verilog weight file\n",
    "- `dpd_trained.pt` - PyTorch checkpoint"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
