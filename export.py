#!/usr/bin/env python3
"""
Weight Export Script for 6G PA DPD System

Exports trained PyTorch TDNN weights to:
1. Verilog $readmemh format for RTL simulation
2. Binary format for FPGA BRAM initialization
3. C header files for embedded software
"""

import argparse
import numpy as np
import torch
import yaml
from pathlib import Path
import struct

from models import TDNNGenerator
from utils.quantization import quantize_weights_fixed_point


def load_checkpoint(checkpoint_path: str, config: dict) -> TDNNGenerator:
    """Load trained model from checkpoint."""
    model = TDNNGenerator(
        memory_depth=config['model']['generator'].get('memory_depth', 5),
        hidden_dims=config['model']['generator'].get('hidden_dims', [32, 16]),
        leaky_slope=config['model']['generator'].get('leaky_slope', 0.2)
    )
    
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    model.load_state_dict(checkpoint['generator_state_dict'])
    model.eval()
    
    return model


def export_verilog_hex(weights: np.ndarray, filepath: Path, 
                       bits: int = 16, values_per_line: int = 1):
    """Export weights to Verilog $readmemh format."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    with open(filepath, 'w') as f:
        f.write(f"// Weight file: {filepath.name}\n")
        f.write(f"// Total weights: {len(weights)}\n")
        f.write(f"// Format: Q1.{bits-1} signed fixed-point\n")
        f.write(f"// Generated by export.py\n\n")
        
        for i, w in enumerate(weights.flatten()):
            # Convert to signed fixed-point integer
            w_int = int(w)
            
            # Handle negative numbers (2's complement)
            if w_int < 0:
                w_int = (1 << bits) + w_int
            
            # Write hex value
            hex_str = format(w_int & ((1 << bits) - 1), f'0{bits//4}X')
            f.write(f"{hex_str}\n")
    
    print(f"Exported {len(weights.flatten())} weights to {filepath}")


def export_binary(weights: np.ndarray, filepath: Path, bits: int = 16):
    """Export weights to binary format for BRAM initialization."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    with open(filepath, 'wb') as f:
        for w in weights.flatten():
            w_int = int(w)
            if bits == 16:
                # Pack as signed 16-bit
                f.write(struct.pack('<h', w_int))
            elif bits == 8:
                f.write(struct.pack('<b', w_int))
            elif bits == 32:
                f.write(struct.pack('<i', w_int))
    
    print(f"Exported binary weights to {filepath}")


def export_c_header(weights: dict, filepath: Path, bits: int = 16):
    """Export weights as C header file for embedded software."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    
    with open(filepath, 'w') as f:
        f.write("// Auto-generated DPD weight header\n")
        f.write("// Do not edit manually\n\n")
        f.write("#ifndef DPD_WEIGHTS_H\n")
        f.write("#define DPD_WEIGHTS_H\n\n")
        f.write("#include <stdint.h>\n\n")
        
        type_str = f"int{bits}_t"
        
        for name, w in weights.items():
            w_flat = w.flatten()
            safe_name = name.replace('.', '_')
            
            f.write(f"// {name}: shape {w.shape}\n")
            f.write(f"static const {type_str} {safe_name}[{len(w_flat)}] = {{\n")
            
            # Write values
            for i, val in enumerate(w_flat):
                val_int = int(val)
                if i % 8 == 0:
                    f.write("    ")
                f.write(f"{val_int:6d}")
                if i < len(w_flat) - 1:
                    f.write(", ")
                if (i + 1) % 8 == 0:
                    f.write("\n")
            
            f.write("\n};\n\n")
        
        f.write("#endif // DPD_WEIGHTS_H\n")
    
    print(f"Exported C header to {filepath}")


def export_temperature_banks(model: TDNNGenerator, base_path: Path, 
                             config: dict) -> dict:
    """
    Export weight banks for different temperature states.
    
    For cold/hot, applies scaling factors from config.
    """
    bits = config['quantization']['weight_bits']
    temp_config = config['pa']
    
    banks = {
        'normal': {},
        'cold': {},
        'hot': {}
    }
    
    # Extract base weights
    for name, param in model.named_parameters():
        if 'weight' in name or 'bias' in name:
            w_float = param.detach().cpu().numpy()
            w_fixed = quantize_weights_fixed_point(
                torch.tensor(w_float), 
                num_bits=bits
            ).numpy()
            banks['normal'][name] = w_fixed
    
    # Apply temperature drift coefficients
    cold_scale = 1.0 + temp_config['cold_drift_factor']
    hot_scale = 1.0 + temp_config['hot_drift_factor']
    
    for name, w in banks['normal'].items():
        # Scale weights for temperature compensation
        banks['cold'][name] = (w * cold_scale).astype(np.int16)
        banks['hot'][name] = (w * hot_scale).astype(np.int16)
    
    # Export each bank
    for temp, weights in banks.items():
        bank_path = base_path / temp
        
        # Combined weight file for RTL
        all_weights = []
        for name in sorted(weights.keys()):
            all_weights.extend(weights[name].flatten())
        
        export_verilog_hex(
            np.array(all_weights), 
            bank_path / 'weights.hex',
            bits=bits
        )
        
        export_binary(
            np.array(all_weights),
            bank_path / 'weights.bin',
            bits=bits
        )
    
    return banks


def main():
    parser = argparse.ArgumentParser(
        description='Export trained DPD weights for FPGA deployment'
    )
    parser.add_argument(
        '--checkpoint', '-c',
        type=str,
        required=True,
        help='Path to trained model checkpoint'
    )
    parser.add_argument(
        '--config', '-f',
        type=str,
        default='config/config.yaml',
        help='Path to config file'
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='rtl/weights',
        help='Output directory for weight files'
    )
    parser.add_argument(
        '--format',
        type=str,
        nargs='+',
        default=['hex', 'bin', 'header'],
        choices=['hex', 'bin', 'header', 'all'],
        help='Export formats'
    )
    parser.add_argument(
        '--temperature-banks',
        action='store_true',
        help='Export separate weight banks for cold/normal/hot'
    )
    args = parser.parse_args()
    
    # Load config
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)
    
    # Load model
    print(f"Loading checkpoint: {args.checkpoint}")
    model = load_checkpoint(args.checkpoint, config)
    
    output_path = Path(args.output)
    bits = config['quantization']['weight_bits']
    
    if 'all' in args.format:
        args.format = ['hex', 'bin', 'header']
    
    if args.temperature_banks:
        # Export temperature-specific weight banks
        print("\nExporting temperature weight banks...")
        banks = export_temperature_banks(model, output_path, config)
        
        # Also export C header with all banks
        if 'header' in args.format:
            all_weights = {}
            for temp, weights in banks.items():
                for name, w in weights.items():
                    all_weights[f"{temp}_{name}"] = w
            export_c_header(all_weights, output_path / 'dpd_weights.h', bits)
    
    else:
        # Export single weight set
        weights = {}
        all_weights = []
        
        for name, param in model.named_parameters():
            if 'weight' in name or 'bias' in name:
                w_float = param.detach().cpu().numpy()
                w_fixed = quantize_weights_fixed_point(
                    torch.tensor(w_float),
                    num_bits=bits
                ).numpy()
                weights[name] = w_fixed
                all_weights.extend(w_fixed.flatten())
        
        all_weights = np.array(all_weights)
        
        if 'hex' in args.format:
            export_verilog_hex(all_weights, output_path / 'weights.hex', bits)
        
        if 'bin' in args.format:
            export_binary(all_weights, output_path / 'weights.bin', bits)
        
        if 'header' in args.format:
            export_c_header(weights, output_path / 'dpd_weights.h', bits)
    
    # Print summary
    print("\n" + "=" * 60)
    print("Export Summary")
    print("=" * 60)
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"Total parameters: {total_params}")
    print(f"Weight bits: {bits}")
    print(f"Memory size: {total_params * bits // 8} bytes")
    print(f"Output directory: {output_path}")
    
    # Layer breakdown
    print("\nLayer breakdown:")
    for name, param in model.named_parameters():
        print(f"  {name}: {list(param.shape)} = {param.numel()}")


if __name__ == '__main__':
    main()
